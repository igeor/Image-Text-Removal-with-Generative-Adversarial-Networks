{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit ('virtual_environment': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "5b060cddb4cf56486a01ae1b618b2d74e063d91b6e79f30e3bcabf21dbdb2c81"
   }
  },
  "interpreter": {
   "hash": "5b060cddb4cf56486a01ae1b618b2d74e063d91b6e79f30e3bcabf21dbdb2c81"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet import *\n",
    "\n",
    "unet = UNet(in_channels=3, out_channels=4)\n",
    "\n",
    "in_image = torch.zeros(4,3,256,256)\n",
    "unet(in_image); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([4, 3, 256, 256])\n",
      "torch.Size([4, 48, 128, 128]) : p1\n",
      "torch.Size([4, 48, 64, 64]) : p2\n",
      "torch.Size([4, 48, 32, 32]) : p3\n",
      "torch.Size([4, 48, 16, 16]) : p4\n",
      "torch.Size([4, 48, 8, 8]) : p5\n",
      "torch.Size([4, 48, 16, 16]) : u5\n",
      "torch.Size([4, 48, 32, 32]) : u4\n",
      "torch.Size([4, 48, 64, 64]) : u3\n",
      "torch.Size([4, 48, 128, 128]) : u2\n",
      "torch.Size([4, 48, 256, 256]) : u1\n",
      "torch.Size([4, 3, 256, 256]) : u0\n"
     ]
    }
   ],
   "source": [
    "from ae import *\n",
    "\n",
    "ae = AutoEncoder(in_channels=3, out_channels=3)\n",
    "\n",
    "in_image = torch.zeros(4,3,256,256)\n",
    "ae(in_image); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([4, 64, 128, 128])\n",
      "torch.Size([4, 128, 64, 64])\n",
      "torch.Size([4, 256, 32, 32])\n",
      "torch.Size([4, 512, 16, 16])\n",
      "torch.Size([4, 512, 8, 8])\n",
      "torch.Size([4, 512, 4, 4])\n",
      "torch.Size([4, 512, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 1024, 4, 4])\n",
      "torch.Size([4, 1024, 8, 8])\n",
      "torch.Size([4, 1024, 16, 16])\n",
      "torch.Size([4, 512, 32, 32])\n",
      "torch.Size([4, 256, 64, 64])\n",
      "torch.Size([4, 64, 128, 128])\n",
      "torch.Size([4, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "from deep_unet import *\n",
    "\n",
    "d_unet = Generator(3, 3)\n",
    "\n",
    "in_image = torch.zeros(4,3,256,256)\n",
    "d_unet(in_image); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([4, 6, 256, 256])\n",
      "torch.Size([4, 64, 128, 128])\n",
      "torch.Size([4, 128, 64, 64])\n",
      "torch.Size([4, 256, 32, 32])\n",
      "torch.Size([4, 512, 31, 31])\n",
      "torch.Size([4, 1, 30, 30])\n"
     ]
    }
   ],
   "source": [
    "from patchgan import * \n",
    "\n",
    "disc = PatchGAN(3 + 3)\n",
    "\n",
    "in_image = torch.zeros(4,3,256,256)\n",
    "real_image = torch.zeros(4,3,256,256)\n",
    "\n",
    "disc(in_image, real_image); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([4, 64, 128, 128])\n",
      "torch.Size([4, 64, 64, 64])\n",
      "torch.Size([4, 64, 32, 32])\n",
      "torch.Size([4, 64, 16, 16])\n",
      "torch.Size([4, 64, 8, 8])\n",
      "torch.Size([4, 64, 16, 16])\n",
      "torch.Size([4, 128, 32, 32])\n",
      "torch.Size([4, 128, 64, 64])\n",
      "torch.Size([4, 128, 128, 128])\n",
      "torch.Size([4, 128, 256, 256])\n",
      "torch.Size([4, 4, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from unet64 import *\n",
    "\n",
    "unet = UNet64(in_channels=3, out_channels=4)\n",
    "\n",
    "in_image = torch.zeros(4,3,256,256)\n",
    "unet(in_image); \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ad96ec474d0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mattunet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKonIQDataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTestDataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSynthTextDataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "from attunet import *\n",
    "from datasets.KonIQDataset import *\n",
    "from datasets.TestDataset import * \n",
    "from datasets.SynthTextDataset import *\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "attunet = AttU_Net(img_ch=3, output_ch=3).to(device='cuda')\n",
    "attunet.load_state_dict(torch.load('/home/igeorvasilis/thesis_src/checkpoints/latest_Gatt{+14}.pth'))\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "\t\ttorchvision.transforms.ToTensor(),\n",
    "\t\ttorchvision.transforms.Resize((256,256))\n",
    "])\n",
    "\t#torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "\t#\t\t\t\t\t\tstd=[0.229, 0.224, 0.225])\n",
    "\n",
    "dataset = KonIQDataset('/home/igeorvasilis/sdb/KoniQ_dataset/B/train', transform=transform)\n",
    "dataset = SynthTextDataset(transform=transform, extra_text=True)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=4)\n",
    "\n",
    "TEST_ROOT = \"/home/igeorvasilis/diploma thesis/noise2noise-pytorch-master/data/test_out/test\"\n",
    "test_dataset = TestDataset(TEST_ROOT, transform=transform, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "\n",
    "attunet(in_image); \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}