{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "import torchvision\n",
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "from networks.ae import AutoEncoder\n",
    "from utils.train_options import *\n",
    "from networks.patchgan import *\n",
    "from networks.deep_unet import *\n",
    "from networks.unet import *\n",
    "from networks.unet64 import *\n",
    "from networks.attunet import *\n",
    "from datasets.KonIQDataset import *\n",
    "from datasets.TestDataset import * \n",
    "from datasets.SynthTextDataset import *\n",
    "from datasets.ValidDataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "gen = AttU_Net(img_ch=3, output_ch=3)\n",
    "gen.load_state_dict(torch.load('/home/igeorvasilis/thesis_src/checkpoints/latest_Gatt(L1c).pth'))\n",
    "#gen = UNet()\n",
    "#gen.load_state_dict(torch.load('/home/igeorvasilis/thesis_src/checkpoints/latest_G_all_20.pth'))\n",
    "gen = gen.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "\t\ttorchvision.transforms.ToTensor(),\n",
    "\t\ttorchvision.transforms.Resize((256,512))\n",
    "])\n",
    "\n",
    "dataset = ValidDataset('/home/igeorvasilis/sdb/KoniQ_dataset/A_B/test', transform=transform)\n",
    "test_loader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test(17).png', 'test(18).png', 'test(19).png', 'test(20).png', 'test(21).png', 'test(22).png', 'test(23).png', 'test(24).png', 'test(25).png', 'test(26).png', 'test(27).png', 'test(28).png', 'test(29).png', 'test(30).png', 'test(31).png', 'test(32).png', 'test1.png', 'test10.png', 'test11.png', 'test12.png', 'test13.png', 'test14.png', 'test15.png', 'test16.png', 'test2.png', 'test3.png', 'test4.png', 'test5.png', 'test6.png', 'test7.png', 'test8.png', 'test9.png']\n"
     ]
    }
   ],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "\t\ttorchvision.transforms.ToTensor(),\n",
    "\t\ttorchvision.transforms.Resize((256,256))\n",
    "])\n",
    "\n",
    "\n",
    "TEST_ROOT = \"/home/igeorvasilis/diploma thesis/noise2noise-pytorch-master/data/test_out/test\"\n",
    "test_dataset = TestDataset(TEST_ROOT, transform=transform, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_id, (condition) in enumerate(test_loader):\n",
    "    condition = condition.to(device)\n",
    "    with torch.no_grad():\n",
    "        fake = gen(condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSNR(img1, img2):\n",
    "    \"\"\"Peak Signal to Noise Ratio\n",
    "    img1 and img2 have range [0, 255]\"\"\"\n",
    "    img1 *= 255.0\n",
    "    img2 *= 255.0 \n",
    "    \n",
    "    mse = torch.mean((img1 - img2) ** 2)\n",
    "    return 20 * torch.log10(255.0 / torch.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ipykernel_launcher:34: UserWarning: DEPRECATED: skimage.measure.compare_ssim has been moved to skimage.metrics.structural_similarity. It will be removed from skimage.measure in version 0.18.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(19.9091, device='cuda:0'), 0.664220593055369)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skimage.measure import compare_ssim\n",
    "\n",
    "psnr_score = 0.0\n",
    "ssim_score = 0.0\n",
    "for batch_id, (input_image) in enumerate(test_loader):\n",
    "    \n",
    "    input_image = input_image[0].to(device)\n",
    "\n",
    "    image_width = input_image.shape[2]\n",
    "    condition = input_image[:, :, :image_width // 2].unsqueeze(0)\n",
    "    target = input_image[:, :, image_width // 2:].unsqueeze(0)\n",
    "    #condition = input_image[:, :, :input_image.shape[2] // 2].unsqueeze(0)\n",
    "    #target = input_image[:, :, input_image.shape[2] // 2 :].unsqueeze(0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        fake = gen(condition)\n",
    "    psnr_score += PSNR(fake, target) / len(test_loader)\n",
    "\n",
    "    fake = fake.to(device='cpu')\n",
    "    condition = condition.to(device='cpu')\n",
    "    target = target.to(device='cpu')\n",
    "\n",
    "    #print(target.shape, condition.shape)\n",
    "    save_image(target, 'o.png')\n",
    "\n",
    "    target = target[0].permute(1, 2, 0).numpy()\n",
    "    fake = fake[0].permute(1, 2, 0).numpy()\n",
    "    condition = condition[0].permute(1, 2, 0).numpy()\n",
    "    \n",
    "    fake = cv2.cvtColor(fake, cv2.COLOR_BGR2GRAY)\n",
    "    target = cv2.cvtColor(target, cv2.COLOR_BGR2GRAY)\n",
    "    condition = cv2.cvtColor(condition, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    (score, diff) = compare_ssim(fake, target, full=True)\n",
    "    diff = (diff * 255).astype(\"uint8\")\n",
    "    \n",
    "    ssim_score += score / len(test_loader)\n",
    "\n",
    "psnr_score, ssim_score\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5b060cddb4cf56486a01ae1b618b2d74e063d91b6e79f30e3bcabf21dbdb2c81"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('virtual_environment': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}