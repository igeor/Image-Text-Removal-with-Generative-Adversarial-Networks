{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet import *\n",
    "\n",
    "unet = UNet(in_channels=3, out_channels=4)\n",
    "\n",
    "in_image = torch.zeros(4,3,256,256)\n",
    "unet(in_image); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 256, 256])\n",
      "torch.Size([4, 48, 128, 128]) : p1\n",
      "torch.Size([4, 48, 64, 64]) : p2\n",
      "torch.Size([4, 48, 32, 32]) : p3\n",
      "torch.Size([4, 48, 16, 16]) : p4\n",
      "torch.Size([4, 48, 8, 8]) : p5\n",
      "torch.Size([4, 48, 16, 16]) : u5\n",
      "torch.Size([4, 48, 32, 32]) : u4\n",
      "torch.Size([4, 48, 64, 64]) : u3\n",
      "torch.Size([4, 48, 128, 128]) : u2\n",
      "torch.Size([4, 48, 256, 256]) : u1\n",
      "torch.Size([4, 3, 256, 256]) : u0\n"
     ]
    }
   ],
   "source": [
    "from ae import *\n",
    "\n",
    "ae = AutoEncoder(in_channels=3, out_channels=3)\n",
    "\n",
    "in_image = torch.zeros(4,3,256,256)\n",
    "ae(in_image); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 64, 128, 128])\n",
      "torch.Size([4, 128, 64, 64])\n",
      "torch.Size([4, 256, 32, 32])\n",
      "torch.Size([4, 512, 16, 16])\n",
      "torch.Size([4, 512, 8, 8])\n",
      "torch.Size([4, 512, 4, 4])\n",
      "torch.Size([4, 512, 2, 2])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 1024, 2, 2])\n",
      "torch.Size([4, 1024, 4, 4])\n",
      "torch.Size([4, 1024, 8, 8])\n",
      "torch.Size([4, 1024, 16, 16])\n",
      "torch.Size([4, 512, 32, 32])\n",
      "torch.Size([4, 256, 64, 64])\n",
      "torch.Size([4, 64, 128, 128])\n",
      "torch.Size([4, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "from deep_unet import *\n",
    "\n",
    "d_unet = Generator(3, 3)\n",
    "\n",
    "in_image = torch.zeros(4,3,256,256)\n",
    "d_unet(in_image); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 6, 256, 256])\n",
      "torch.Size([4, 64, 128, 128])\n",
      "torch.Size([4, 128, 64, 64])\n",
      "torch.Size([4, 256, 32, 32])\n",
      "torch.Size([4, 512, 31, 31])\n",
      "torch.Size([4, 1, 30, 30])\n"
     ]
    }
   ],
   "source": [
    "from patchgan import * \n",
    "\n",
    "disc = PatchGAN(3 + 3)\n",
    "\n",
    "in_image = torch.zeros(4,3,256,256)\n",
    "real_image = torch.zeros(4,3,256,256)\n",
    "\n",
    "disc(in_image, real_image); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 64, 128, 128])\n",
      "torch.Size([4, 64, 64, 64])\n",
      "torch.Size([4, 64, 32, 32])\n",
      "torch.Size([4, 64, 16, 16])\n",
      "torch.Size([4, 64, 8, 8])\n",
      "torch.Size([4, 64, 16, 16])\n",
      "torch.Size([4, 128, 32, 32])\n",
      "torch.Size([4, 128, 64, 64])\n",
      "torch.Size([4, 128, 128, 128])\n",
      "torch.Size([4, 128, 256, 256])\n",
      "torch.Size([4, 4, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from unet64 import *\n",
    "\n",
    "unet = UNet64(in_channels=3, out_channels=4)\n",
    "\n",
    "in_image = torch.zeros(4,3,256,256)\n",
    "unet(in_image); \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block1(e1)-> torch.Size([1, 64, 128, 128])\n",
      "block2(e2)-> torch.Size([1, 64, 64, 64])\n",
      "block3(e3)-> torch.Size([1, 64, 32, 32])\n",
      "block4(e4)-> torch.Size([1, 64, 16, 16])\n",
      "block5(e5)-> torch.Size([1, 64, 8, 8])\n",
      "up5(e6)-> torch.Size([1, 64, 16, 16])\n",
      "torch.Size([1, 64, 16, 16]) torch.Size([1, 64, 16, 16])\n",
      "torch.Size([1, 64, 16, 16]) torch.Size([1, 64, 16, 16])\n",
      "torch.Size([1, 64, 16, 16])\n",
      "torch.Size([1, 1, 16, 16])\n",
      "torch.Size([1, 1, 16, 16])\n",
      "Att5(g=d6, x=e5)-> torch.Size([1, 64, 16, 16]) torch.Size([1, 64, 16, 16])\n",
      "d6.shape:  torch.Size([1, 128, 16, 16])\n",
      "Up_conv5(d6)-> torch.Size([1, 64, 16, 16])\n",
      "up4(e4)-> torch.Size([1, 64, 32, 32])\n",
      "torch.Size([1, 64, 32, 32]) torch.Size([1, 64, 32, 32])\n",
      "torch.Size([1, 64, 32, 32]) torch.Size([1, 64, 32, 32])\n",
      "torch.Size([1, 64, 32, 32])\n",
      "torch.Size([1, 1, 32, 32])\n",
      "torch.Size([1, 1, 32, 32])\n",
      "Att4(g=d5, x=e4)-> torch.Size([1, 64, 32, 32])\n",
      "d5.shape:  torch.Size([1, 128, 32, 32])\n",
      "Up_conv4(d5)-> torch.Size([1, 64, 32, 32])\n",
      "up3(d4)-> torch.Size([1, 64, 64, 64])\n",
      "torch.Size([1, 64, 64, 64]) torch.Size([1, 64, 64, 64])\n",
      "torch.Size([1, 64, 64, 64]) torch.Size([1, 64, 64, 64])\n",
      "torch.Size([1, 64, 64, 64])\n",
      "torch.Size([1, 1, 64, 64])\n",
      "torch.Size([1, 1, 64, 64])\n",
      "Att3(g=d4, x=e3)-> torch.Size([1, 64, 64, 64])\n",
      "d4.shape:  torch.Size([1, 128, 64, 64])\n",
      "Up_conv3(d4)-> torch.Size([1, 64, 64, 64])\n",
      "up2(d3)-> torch.Size([1, 64, 128, 128])\n",
      "torch.Size([1, 64, 128, 128]) torch.Size([1, 64, 128, 128])\n",
      "torch.Size([1, 32, 128, 128]) torch.Size([1, 32, 128, 128])\n",
      "torch.Size([1, 32, 128, 128])\n",
      "torch.Size([1, 1, 128, 128])\n",
      "torch.Size([1, 1, 128, 128])\n",
      "Att2(g=d3, x=e2)-> torch.Size([1, 64, 128, 128])\n",
      "d3.shape:  torch.Size([1, 128, 128, 128])\n",
      "Up_conv2(d3)-> torch.Size([1, 64, 128, 128])\n",
      "up2(d2)-> torch.Size([1, 64, 256, 256])\n",
      "torch.Size([1, 64, 256, 256]) torch.Size([1, 64, 256, 256])\n",
      "torch.Size([1, 32, 256, 256]) torch.Size([1, 32, 256, 256])\n",
      "torch.Size([1, 32, 256, 256])\n",
      "torch.Size([1, 1, 256, 256])\n",
      "torch.Size([1, 1, 256, 256])\n",
      "Att2(g=d2, x=e1)-> torch.Size([1, 64, 256, 256])\n",
      "d2.shape:  torch.Size([1, 128, 256, 256])\n",
      "Up_conv2(d2)-> torch.Size([1, 64, 256, 256])\n",
      "Conv(d3)-> torch.Size([1, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "from networks.attunet import *\n",
    "\n",
    "attunet = AttU_Net(img_ch=3, output_ch=3)\n",
    "\n",
    "in_image = torch.zeros(1,3,256,256)\n",
    "attunet(in_image); \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SynthText Dataset contains:  (858750,) image names. ['test(17).png', 'test(18).png', 'test(19).png', 'test(20).png', 'test(21).png', 'test(22).png', 'test(23).png', 'test(24).png', 'test(25).png', 'test(26).png', 'test(27).png', 'test(28).png', 'test(29).png', 'test(30).png', 'test(31).png', 'test(32).png', 'test1.png', 'test10.png', 'test11.png', 'test12.png', 'test13.png', 'test14.png', 'test15.png', 'test16.png', 'test2.png', 'test3.png', 'test4.png', 'test5.png', 'test6.png', 'test7.png', 'test8.png', 'test9.png']\n"
     ]
    }
   ],
   "source": [
    "from networks.attunet import *\n",
    "from datasets.KonIQDataset import *\n",
    "from datasets.TestDataset import * \n",
    "from datasets.SynthTextDataset import *\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "attunet = AttU_Net(img_ch=3, output_ch=3).to(device='cuda')\n",
    "attunet.load_state_dict(torch.load('/home/igeorvasilis/thesis_src/checkpoints/latest_Gatt{+14}.pth'))\n",
    "\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "\t\ttorchvision.transforms.ToTensor(),\n",
    "\t\ttorchvision.transforms.Resize((256,256))\n",
    "])\n",
    "\t#torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "\t#\t\t\t\t\t\tstd=[0.229, 0.224, 0.225])\n",
    "\n",
    "dataset = KonIQDataset('/home/igeorvasilis/sdb/KoniQ_dataset/B/train', transform=transform)\n",
    "dataset = SynthTextDataset(transform=transform, extra_text=True)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=4)\n",
    "\n",
    "TEST_ROOT = \"/home/igeorvasilis/diploma thesis/noise2noise-pytorch-master/data/test_out/test\"\n",
    "test_dataset = TestDataset(TEST_ROOT, transform=transform, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1)\n",
    "\n",
    "\n",
    "#condition = torch.zeros(1,3,256,256).to(device='cuda')\n",
    "for batch_id, (condition) in enumerate(test_loader):\n",
    "    condition = condition.to(device)\n",
    "    with torch.no_grad():\n",
    "        fake = attunet(condition)\n",
    "    #save_image(out, \"psi\"+str(batch_id)+\".png\")  \n",
    "\n",
    "\n",
    "fake = attunet(condition)\n",
    "for i in range(fake.shape[1]): \n",
    "    save_image(fake[:,i,:,:], \"1.png\")   \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5b060cddb4cf56486a01ae1b618b2d74e063d91b6e79f30e3bcabf21dbdb2c81"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('virtual_environment': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "metadata": {
   "interpreter": {
    "hash": "5b060cddb4cf56486a01ae1b618b2d74e063d91b6e79f30e3bcabf21dbdb2c81"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}